{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "TOPIC :Email Spam Detection Using Machine Learning Algorithms"
      ],
      "metadata": {
        "id": "EEkf9lOoXzG0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SPAM EMAIL detection using KNN , SVM, Naive Bayes,Decision Tree and Hybrid (NB+SVM)**"
      ],
      "metadata": {
        "id": "o7on8Yptfce-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Import Libraries"
      ],
      "metadata": {
        "id": "4qdpCpIieRMW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0niaw3NeM9F"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from scipy.sparse import hstack\n",
        "import re\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Load Dataset"
      ],
      "metadata": {
        "id": "7VodmoFFeTOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('spam.csv', encoding='latin-1')[['v1', 'v2']]\n",
        "df.columns = ['label', 'message']\n",
        "\n"
      ],
      "metadata": {
        "id": "LlMnY9ELeVV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Exploratory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "Xur9OIMleYCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nClass Distribution:\\n\", df['label'].value_counts())\n",
        "sns.countplot(x='label', data=df)\n",
        "plt.title(\"Class Distribution: Ham vs Spam\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "klHdryVseacr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Text Length Distribution"
      ],
      "metadata": {
        "id": "UPOaS1rReb3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_length'] = df['message'].apply(len)\n",
        "sns.boxplot(x='label', y='text_length', data=df)\n",
        "plt.yscale('log')\n",
        "plt.title(\"Text Length by Class\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CISY6307ehAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Clean and Preprocess Text"
      ],
      "metadata": {
        "id": "_pHg3UTeekN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
        "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "df['cleaned_message'] = df['message'].apply(clean_text)\n",
        "df['text_length'] = df['cleaned_message'].apply(len)\n"
      ],
      "metadata": {
        "id": "I4BvlExyellB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: TF-IDF Vectorization + Additional Feature"
      ],
      "metadata": {
        "id": "4cI3v1zteowF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "X_tfidf = vectorizer.fit_transform(df['cleaned_message'])\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "text_length_scaled = scaler.fit_transform(df[['text_length']])\n",
        "\n",
        "X_combined = hstack([X_tfidf, text_length_scaled])\n",
        "y = LabelEncoder().fit_transform(df['label'])  # spam=1, ham=0\n"
      ],
      "metadata": {
        "id": "Enl1Mzflepnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Balance Dataset with SMOTE"
      ],
      "metadata": {
        "id": "MlTWJ1KgesBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Class distribution before SMOTE:\", Counter(y))\n",
        "\n",
        "if df['label'].value_counts().min() / df['label'].value_counts().max() < 0.5:\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_combined, y = smote.fit_resample(X_combined, y)\n",
        "    print(\"Class distribution after SMOTE:\", Counter(y))\n"
      ],
      "metadata": {
        "id": "vxIaDwn9etl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8: Train-Test Split"
      ],
      "metadata": {
        "id": "osHF2GMlewGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "iH7-1IO1ew7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 9: Define and Train Models"
      ],
      "metadata": {
        "id": "BMUQ3ZiTezkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"Naive Bayes\": MultinomialNB(),\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
        "    \"SVM\": SVC(kernel='linear'),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "}\n"
      ],
      "metadata": {
        "id": "5ruE1KCGe0RQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 10: Hybrid Model"
      ],
      "metadata": {
        "id": "f1xWoVK4e3Mb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HybridModel:\n",
        "    def __init__(self):\n",
        "        self.nb = MultinomialNB()\n",
        "        self.svm = SVC(kernel='linear')\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.nb.fit(X, y)\n",
        "        svm_train_idx = (self.nb.predict_proba(X)[:, 1] > 0.3)\n",
        "        self.svm.fit(X[svm_train_idx], y[svm_train_idx])\n",
        "\n",
        "    def predict(self, X):\n",
        "        nb_pred = self.nb.predict(X)\n",
        "        svm_pred = self.svm.predict(X)\n",
        "        return np.where(nb_pred == 0, nb_pred, svm_pred)\n",
        "\n",
        "models[\"Hybrid (NB+SVM)\"] = HybridModel()\n"
      ],
      "metadata": {
        "id": "GZ2CAYNle4JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 11: Model Evaluation"
      ],
      "metadata": {
        "id": "-hBzpov9e7Ft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    results.append({\n",
        "        \"Model\": name,\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Recall\": recall_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"F1-Score\": f1_score(y_test, y_pred)\n",
        "    })\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "id": "RLobiTaVe75d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 12: Visualization"
      ],
      "metadata": {
        "id": "5-uawpmne-6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "x = np.arange(len(models))\n",
        "width = 0.25\n",
        "for i, metric in enumerate(['Accuracy', 'Recall', 'Precision']):\n",
        "    rects = ax.bar(x + i * width, results_df[metric], width, label=metric)\n",
        "    ax.bar_label(rects, fmt='%.2f', padding=3)\n",
        "\n",
        "ax.set_xticks(x + width)\n",
        "ax.set_xticklabels(results_df['Model'], rotation=45)\n",
        "ax.set_title('Model Comparison')\n",
        "ax.legend()\n",
        "plt.ylim(0.8, 1.05)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VKoUetrde_8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 13: Confusion Matrix for Best Model"
      ],
      "metadata": {
        "id": "c7CqUNZGfCve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = results_df.loc[results_df['F1-Score'].idxmax(), 'Model']\n",
        "model = models[best_model]\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Ham', 'Spam'],\n",
        "            yticklabels=['Ham', 'Spam'])\n",
        "plt.title(f'Confusion Matrix - {best_model}')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wgq6gL2VfDZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 14: Word Clouds"
      ],
      "metadata": {
        "id": "k01w5cjxfGLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spam_words = ' '.join(df[df['label'] == 'spam']['cleaned_message'])\n",
        "ham_words = ' '.join(df[df['label'] == 'ham']['cleaned_message'])\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
        "ax1.imshow(WordCloud(width=800, height=400).generate(spam_words))\n",
        "ax1.axis('off')\n",
        "ax1.set_title(\"Spam Word Cloud\")\n",
        "\n",
        "ax2.imshow(WordCloud(width=800, height=400).generate(ham_words))\n",
        "ax2.axis('off')\n",
        "ax2.set_title(\"Ham Word Cloud\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0y4EtT1gfHVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking model"
      ],
      "metadata": {
        "id": "KkH07ciuIOI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "\n",
        "display(HTML(\"\"\"\n",
        "<style>\n",
        "    .widget-label { font-size: 16px !important; color: #f0f0f0; font-weight: bold; }\n",
        "    .widget-textarea textarea { background-color: #1e1e1e !important; color: #ffffff !important; font-family: monospace; font-size: 15px; border: 1px solid #555; border-radius: 8px; padding: 10px; }\n",
        "    .widget-button { background-color: #27ae60 !important; color: white !important; border-radius: 8px; font-weight: bold; }\n",
        "</style>\n",
        "\"\"\"))\n",
        "\n",
        "\n",
        "input_box = widgets.Textarea(\n",
        "    value='',\n",
        "    placeholder='‚úçÔ∏è Type or paste an email/message here...',\n",
        "    description='üì© Message:',\n",
        "    layout=widgets.Layout(width='100%', height='100px'),\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "predict_btn = widgets.Button(\n",
        "    description='üîç Classify',\n",
        "    button_style='success',\n",
        "    tooltip='Click to classify message',\n",
        "    layout=widgets.Layout(width='150px', height='40px')\n",
        ")\n",
        "\n",
        "result_box = widgets.HTML(value=\"\")\n",
        "\n",
        "\n",
        "def classify_message(b):\n",
        "    msg = input_box.value.strip()\n",
        "    if not msg:\n",
        "        result_box.value = \"<span style='color:#e74c3c;font-size:16px'>‚ö†Ô∏è Please enter a message.</span>\"\n",
        "        return\n",
        "\n",
        "    cleaned = clean_text(msg)\n",
        "    msg_tfidf = vectorizer.transform([cleaned])\n",
        "    msg_len = scaler.transform(pd.DataFrame({'text_length': [len(cleaned)]}))\n",
        "    msg_features = hstack([msg_tfidf, msg_len])\n",
        "\n",
        "    pred = model.predict(msg_features)[0]\n",
        "    label = 'üö´ <b>SPAM</b>' if pred == 1 else '‚úÖ <b>HAM</b>'\n",
        "    color = '#e74c3c' if pred == 1 else '#2ecc71'\n",
        "\n",
        "    result_box.value = f\"<span style='color:{color}; font-size:20px'>{label}</span>\"\n",
        "\n",
        "predict_btn.on_click(classify_message)\n",
        "\n",
        "\n",
        "display(input_box, predict_btn, result_box)\n"
      ],
      "metadata": {
        "id": "ub_eE7SFIMpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODEL BASED ON HYBRID MODEL : LOGISTIC REGRESSION AND NAIVE BAYES**"
      ],
      "metadata": {
        "id": "1ORRK3aok-uV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Import Libraries"
      ],
      "metadata": {
        "id": "eLH2t3lS3shn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "import re\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from scipy.sparse import hstack\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n"
      ],
      "metadata": {
        "id": "uKlC3T0K2SIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Load and Clean Data"
      ],
      "metadata": {
        "id": "l1UxR3dE2YSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('spam.csv', encoding='latin-1')[['v1', 'v2']]\n",
        "df.columns = ['label', 'message']\n",
        "df"
      ],
      "metadata": {
        "id": "P-iGdbZh2TW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Exploratory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "SZQ2NthL2Z0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\nClass Distribution:\\n\", df['label'].value_counts())\n",
        "sns.countplot(x='label', data=df)\n",
        "plt.title(\"Class Distribution: Ham vs Spam\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DGAYcDqF2eYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4:Analyze Text Length"
      ],
      "metadata": {
        "id": "PonZVG4mQDqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_length'] = df['message'].apply(len)\n",
        "sns.boxplot(x='label', y='text_length', data=df)\n",
        "plt.yscale('log')\n",
        "plt.title(\"Text Length by Class\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qXEriLC8QH-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Clean and Preprocess Text"
      ],
      "metadata": {
        "id": "9-g3O87wQKBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "df['cleaned_message'] = df['message'].apply(clean_text)\n",
        "df['text_length'] = df['cleaned_message'].apply(len)"
      ],
      "metadata": {
        "id": "CxVDSgwzQNLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Label Encoding and TF-IDF + Scaled Length Vectorization"
      ],
      "metadata": {
        "id": "3gFIK2LHQXFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "df['label'] = label_encoder.fit_transform(df['label'])\n",
        "y = df['label']\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "X_tfidf = vectorizer.fit_transform(df['cleaned_message'])\n",
        "scaler = MinMaxScaler()\n",
        "text_length_scaled = scaler.fit_transform(df[['text_length']])\n",
        "X_combined = hstack([X_tfidf, text_length_scaled])\n"
      ],
      "metadata": {
        "id": "NkgENKFFQUOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8: Apply SMOTE for Handling Imbalance"
      ],
      "metadata": {
        "id": "SaUJuHA6QZ85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if df['label'].value_counts().min() / df['label'].value_counts().max() < 0.5:\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_combined, y = smote.fit_resample(X_combined, y)\n",
        "\n"
      ],
      "metadata": {
        "id": "pyi9dgkIQdKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 9: Train-Test Split"
      ],
      "metadata": {
        "id": "BUUUmLu-Qgel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "180D9JEyQftP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 10: Define Hybrid Model (Naive Bayes + logistic regression)"
      ],
      "metadata": {
        "id": "tNgw4S5BQjPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HybridNB_LR:\n",
        "    def __init__(self):\n",
        "        self.nb = MultinomialNB()\n",
        "        self.lr = LogisticRegression(max_iter=1000)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.nb.fit(X, y)\n",
        "        nb_prob = self.nb.predict_proba(X)[:, 1]\n",
        "        confident_idx = nb_prob > 0.8\n",
        "        if np.sum(confident_idx) > 0:\n",
        "            self.lr.fit(X[confident_idx], y[confident_idx])\n",
        "        else:\n",
        "            self.lr.fit(X, y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        nb_pred = self.nb.predict(X)\n",
        "        nb_prob = self.nb.predict_proba(X)[:, 1]\n",
        "        lr_pred = self.lr.predict(X)\n",
        "        final_pred = np.where(nb_prob > 0.8, nb_pred, lr_pred)\n",
        "        return final_pred"
      ],
      "metadata": {
        "id": "iVRGvwlpQ4A4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 11: Model Evaluation"
      ],
      "metadata": {
        "id": "iYDMJq5GQ3fE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hybrid_model = HybridNB_LR()\n",
        "hybrid_model.fit(X_train, y_train)\n",
        "y_pred = hybrid_model.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred))\n",
        "print(\"F1-Score:\", f1_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "A1AUnp4ZRE3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 12: Display Confusion Matrix"
      ],
      "metadata": {
        "id": "ZYZKtm1yRTvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix - Hybrid Model\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jk-odm2iRUTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 13: Word Cloud Visualization"
      ],
      "metadata": {
        "id": "dYeOsH_B28NJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spam_words = ' '.join(df[df['label'] == 1]['cleaned_message'].dropna())\n",
        "ham_words = ' '.join(df[df['label'] == 0]['cleaned_message'].dropna())\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "if spam_words.strip():\n",
        "    ax1.imshow(WordCloud(width=800, height=400).generate(spam_words))\n",
        "    ax1.set_title(\"Spam Word Cloud\")\n",
        "else:\n",
        "    ax1.text(0.5, 0.5, 'No spam words found', fontsize=18, ha='center')\n",
        "ax1.axis('off')\n",
        "\n",
        "if ham_words.strip():\n",
        "    ax2.imshow(WordCloud(width=800, height=400).generate(ham_words))\n",
        "    ax2.set_title(\"Ham Word Cloud\")\n",
        "else:\n",
        "    ax2.text(0.5, 0.5, 'No ham words found', fontsize=18, ha='center')\n",
        "ax2.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "saMJOgKY2_IY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 15: Build GUI for Message Classification"
      ],
      "metadata": {
        "id": "NNbZYq8hRoSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "\n",
        "display(HTML(\"\"\"\n",
        "<style>\n",
        "    .widget-label { font-size: 16px !important; color: #f0f0f0; font-weight: bold; }\n",
        "    .widget-textarea textarea {\n",
        "        background-color: #1e1e1e !important;\n",
        "        color: #ffffff !important;\n",
        "        font-family: monospace;\n",
        "        font-size: 15px;\n",
        "        border: 1px solid #555;\n",
        "        border-radius: 8px;\n",
        "        padding: 10px;\n",
        "    }\n",
        "    .widget-button {\n",
        "        background-color: #27ae60 !important;\n",
        "        color: white !important;\n",
        "        border-radius: 8px;\n",
        "        font-weight: bold;\n",
        "        font-size: 15px;\n",
        "    }\n",
        "    .confidence-bar {\n",
        "        background-color: #ddd;\n",
        "        border-radius: 10px;\n",
        "        overflow: hidden;\n",
        "        margin: 10px 0;\n",
        "    }\n",
        "    .confidence-fill {\n",
        "        height: 24px;\n",
        "        line-height: 24px;\n",
        "        color: white;\n",
        "        text-align: center;\n",
        "        font-weight: bold;\n",
        "    }\n",
        "</style>\n",
        "\"\"\"))\n",
        "\n",
        "\n",
        "input_box = widgets.Textarea(\n",
        "    value='',\n",
        "    placeholder='‚úçÔ∏è Type or paste an email/message here...',\n",
        "    description='üì© Message:',\n",
        "    layout=widgets.Layout(width='100%', height='120px'),\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "\n",
        "predict_btn = widgets.Button(\n",
        "    description='üîç Classify',\n",
        "    button_style='success',\n",
        "    tooltip='Click to classify message',\n",
        "    layout=widgets.Layout(width='150px', height='45px')\n",
        ")\n",
        "\n",
        "\n",
        "result_box = widgets.HTML(value=\"\")\n",
        "\n",
        "\n",
        "def classify_message(b):\n",
        "    msg = input_box.value.strip()\n",
        "    if not msg:\n",
        "        result_box.value = \"<span style='color:#e74c3c;font-size:16px'>‚ö†Ô∏è Please enter a message.</span>\"\n",
        "        return\n",
        "\n",
        "    cleaned = clean_text(msg)\n",
        "    msg_tfidf = vectorizer.transform([cleaned])\n",
        "    msg_len = scaler.transform(pd.DataFrame({'text_length': [len(cleaned)]}))\n",
        "    msg_features = hstack([msg_tfidf, msg_len])\n",
        "\n",
        "\n",
        "    prob_spam = hybrid_model.nb.predict_proba(msg_features)[0][1]\n",
        "    prob_ham = hybrid_model.nb.predict_proba(msg_features)[0][0]\n",
        "    pred = 1 if prob_spam >= 0.5 else 0\n",
        "\n",
        "    label = 'üö´ <b>SPAM</b>' if pred == 1 else '‚úÖ <b>HAM</b>'\n",
        "    label_color = '#e74c3c' if pred == 1 else '#2ecc71'\n",
        "\n",
        "    result_box.value = f\"\"\"\n",
        "    <div style='font-size:20px; font-weight:bold; margin-bottom:10px; color:{label_color};'>{label}</div>\n",
        "\n",
        "    <div>\n",
        "        <div style='margin:5px 0;'>‚úÖ Ham Confidence: {prob_ham * 100:.2f}%</div>\n",
        "        <div class='confidence-bar'>\n",
        "            <div class='confidence-fill' style='width: {prob_ham * 100:.2f}%; background-color: #2ecc71;'>\n",
        "                {prob_ham * 100:.1f}%\n",
        "            </div>\n",
        "        </div>\n",
        "        <div style='margin:5px 0;'>üö´ Spam Confidence: {prob_spam * 100:.2f}%</div>\n",
        "        <div class='confidence-bar'>\n",
        "            <div class='confidence-fill' style='width: {prob_spam * 100:.2f}%; background-color: #e74c3c;'>\n",
        "                {prob_spam * 100:.1f}%\n",
        "            </div>\n",
        "        </div>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "predict_btn.on_click(classify_message)\n",
        "\n",
        "\n",
        "display(input_box, predict_btn, result_box)\n"
      ],
      "metadata": {
        "id": "6ySHI5RTRmNz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}